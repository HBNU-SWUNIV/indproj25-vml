{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e33c7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# gpu = 1\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eba63b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T00:35:32.979533Z",
     "iopub.status.busy": "2025-05-15T00:35:32.979240Z",
     "iopub.status.idle": "2025-05-15T00:36:08.909938Z",
     "shell.execute_reply": "2025-05-15T00:36:08.908985Z"
    },
    "papermill": {
     "duration": 35.936147,
     "end_time": "2025-05-15T00:36:08.911376",
     "exception": false,
     "start_time": "2025-05-15T00:35:32.975229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel, PeftConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bdca7b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T00:36:08.919835Z",
     "iopub.status.busy": "2025-05-15T00:36:08.919262Z",
     "iopub.status.idle": "2025-05-15T00:36:08.924113Z",
     "shell.execute_reply": "2025-05-15T00:36:08.923244Z"
    },
    "papermill": {
     "duration": 0.010484,
     "end_time": "2025-05-15T00:36:08.925544",
     "exception": false,
     "start_time": "2025-05-15T00:36:08.915060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory: special_tocken\n"
     ]
    }
   ],
   "source": [
    "train_csv      = \"/home/work/hhg/train_paragraph_balanced.csv\"\n",
    "test_csv      = \"/home/work/.datasets/test.csv\"\n",
    "model_name     = \"klue/roberta-base\"\n",
    "batch_size     = 32\n",
    "learning_rate  = 1e-4\n",
    "num_epochs     = 30\n",
    "max_length     = 256\n",
    "seed           = 42\n",
    "# %%\n",
    "checkpoint = \"special_tocken\"\n",
    "print(f\"Checkpoint directory: {checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ffafb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecab import MeCab\n",
    "\n",
    "mecab = MeCab()\n",
    "\n",
    "from mecab import MeCab\n",
    "\n",
    "mecab = MeCab()\n",
    "\n",
    "# --- 2. 커스텀 토큰 붙이기 ---\n",
    "def add_custom_tokens(text):\n",
    "    \"\"\"\n",
    "    Mecab으로 형태소 분석 후, AI/인간 텍스트 판별에 도움이 되는 품사에 커스텀 토큰 붙이기\n",
    "    \"\"\"\n",
    "    pos_tags = mecab.pos(text)\n",
    "\n",
    "    # 품사별 붙일 토큰 정의 (판별용으로 추려서 구성)\n",
    "    target_pos = {\n",
    "        # --- 어미 ---\n",
    "        'EF': '_EOS',    # 종결어미\n",
    "        'EC': '_CON',    # 연결어미\n",
    "        'ETM': '_MOD',   # 관형형 어미\n",
    "\n",
    "        # --- 조사 ---\n",
    "        'JKS': '_SUB',   # 주격 조사\n",
    "        'JKO': '_OBJ',   # 목적격 조사\n",
    "        'JKB': '_ADV',   # 부사격 조사\n",
    "        'JKQ': '_QUOTE', # 인용격 조사\n",
    "\n",
    "        # --- 부사 ---\n",
    "        'MAG': '_ADV',      # 일반 부사\n",
    "        'MAJ': '_CONADV',   # 접속 부사\n",
    "\n",
    "        # --- 고유명사 ---\n",
    "        'NNP': '_NAME',\n",
    "\n",
    "        # --- 문장부호 ---\n",
    "        'SF': '_PUNCT',  # 마침표\n",
    "        'SE': '_PUNCT',  # 물음표, 느낌표\n",
    "    }\n",
    "\n",
    "    tokens = []\n",
    "    for morph, pos in pos_tags:\n",
    "        if pos in target_pos:\n",
    "            tokens.append(morph + target_pos[pos])\n",
    "        else:\n",
    "            tokens.append(morph)\n",
    "    return \" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca30658a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T00:36:08.933300Z",
     "iopub.status.busy": "2025-05-15T00:36:08.933022Z",
     "iopub.status.idle": "2025-05-15T00:36:08.943941Z",
     "shell.execute_reply": "2025-05-15T00:36:08.943243Z"
    },
    "papermill": {
     "duration": 0.0162,
     "end_time": "2025-05-15T00:36:08.945257",
     "exception": false,
     "start_time": "2025-05-15T00:36:08.929057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55e4bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\([^)]*\\)', ' ', text)\n",
    "    text = re.sub(r'[ㅎㅜㅠㅡ]+', ' ', text)\n",
    "    text = re.sub(r'[\\r\\n]+', ' ', text)  \n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s.!?]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "571889c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T00:36:08.953452Z",
     "iopub.status.busy": "2025-05-15T00:36:08.953151Z",
     "iopub.status.idle": "2025-05-15T00:36:09.152010Z",
     "shell.execute_reply": "2025-05-15T00:36:09.150815Z"
    },
    "papermill": {
     "duration": 0.204681,
     "end_time": "2025-05-15T00:36:09.153680",
     "exception": true,
     "start_time": "2025-05-15T00:36:08.948999",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_csv)\n",
    "df = df.dropna(subset=['paragraph_text'])\n",
    "df['paragraph_text'] = df['paragraph_text'].astype(str)\n",
    "train_df, val_df = train_test_split(df,test_size=0.3,random_state=seed,stratify=df['generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cee82f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e41cdfb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:16:47.562716Z",
     "iopub.status.busy": "2025-04-22T14:16:47.562419Z",
     "iopub.status.idle": "2025-04-22T14:16:59.745654Z",
     "shell.execute_reply": "2025-04-22T14:16:59.744846Z",
     "shell.execute_reply.started": "2025-04-22T14:16:47.562690Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,  # 이진 분류니까 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4df4c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32010, 768, padding_idx=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- AI/인간 판별용 special tokens 등록 ---\n",
    "special_tokens = [\n",
    "    '_EOS',     # 종결어미\n",
    "    '_CON',     # 연결어미\n",
    "    '_MOD',     # 관형형 어미\n",
    "    '_SUB',     # 주격 조사\n",
    "    '_OBJ',     # 목적격 조사\n",
    "    '_ADV',     # 부사 / 부사격 조사\n",
    "    '_CONADV',  # 접속 부사\n",
    "    '_QUOTE',   # 인용격 조사\n",
    "    '_NAME',    # 고유명사\n",
    "    '_PUNCT'    # 문장부호\n",
    "]\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "\n",
    "# 토크나이저에 추가\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# 모델 임베딩 크기 재조정\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fda01f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(32010, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7ebce8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:16:59.843261Z",
     "iopub.status.busy": "2025-04-22T14:16:59.842993Z",
     "iopub.status.idle": "2025-04-22T14:16:59.848984Z",
     "shell.execute_reply": "2025-04-22T14:16:59.848308Z",
     "shell.execute_reply.started": "2025-04-22T14:16:59.843228Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # special tokens 등록\n",
    "        special_tokens = [\n",
    "            '_EOS',     # 종결어미\n",
    "            '_CON',     # 연결어미\n",
    "            '_MOD',     # 관형형 어미\n",
    "            '_SUB',     # 주격 조사\n",
    "            '_OBJ',     # 목적격 조사\n",
    "            '_ADV',     # 부사 / 부사격 조사\n",
    "            '_CONADV',  # 접속 부사\n",
    "            '_QUOTE',   # 인용격 조사\n",
    "            '_NAME',    # 고유명사\n",
    "            '_PUNCT'    # 문장부호\n",
    "        ]\n",
    "        special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "        self.tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row['paragraph_text']\n",
    "        title = row['title']  # NEW: title 열 추가\n",
    "        \n",
    "        text = clean_text(text)\n",
    "\n",
    "        # 종결어미 특별토큰 붙이는 함수\n",
    "        text = add_custom_tokens(text)\n",
    "\n",
    "        combined_text = f\"[TITLE] {title} [SEP] {text}\"  # NEW: 타이틀과 본문 결합\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            combined_text,  # NEW: combined_text로 토큰화\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        item = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "        item['generated'] = torch.tensor(row['generated'], dtype=torch.long)\n",
    "        \n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3058a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:16:59.851134Z",
     "iopub.status.busy": "2025-04-22T14:16:59.850866Z",
     "iopub.status.idle": "2025-04-22T14:16:59.872381Z",
     "shell.execute_reply": "2025-04-22T14:16:59.871630Z",
     "shell.execute_reply.started": "2025-04-22T14:16:59.851113Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_df, tokenizer, max_length=max_length)\n",
    "val_dataset   = Dataset(val_df, tokenizer, max_length=max_length)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader    = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b7f5517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:17:15.147190Z",
     "iopub.status.busy": "2025-04-22T14:17:15.146913Z",
     "iopub.status.idle": "2025-04-22T14:17:15.153423Z",
     "shell.execute_reply": "2025-04-22T14:17:15.152698Z",
     "shell.execute_reply.started": "2025-04-22T14:17:15.147166Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    progress_bar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['generated'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)[:, 1]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.5\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    \n",
    "    return avg_loss, acc, auc, f1, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "506a814b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:17:15.154445Z",
     "iopub.status.busy": "2025-04-22T14:17:15.154207Z",
     "iopub.status.idle": "2025-04-22T14:17:15.168662Z",
     "shell.execute_reply": "2025-04-22T14:17:15.168031Z",
     "shell.execute_reply.started": "2025-04-22T14:17:15.154423Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    progress_bar = tqdm(loader, desc=\"Validation\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['generated'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)[:, 1]\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix(loss=f\"{outputs.loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.5\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    \n",
    "    return avg_loss, acc, auc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af7a2cb3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_model(model, model_name, tokenizer, train_loader, val_loader, num_epochs, learning_rate, checkpoint):\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    if not os.path.exists(checkpoint):\n",
    "        os.makedirs(checkpoint)\n",
    "\n",
    "    best_auc = 0.0\n",
    "    train_losses, train_aucs, train_f1s = [], [], []\n",
    "    val_losses, val_aucs, val_accs, val_f1s = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss, train_acc, train_auc, train_f1, train_preds, train_labels = train(model, train_loader, optimizer, scheduler, device)\n",
    "        val_loss, val_acc, val_auc, val_f1, val_preds, val_labels = evaluate(model, val_loader, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_aucs.append(train_auc)\n",
    "        train_f1s.append(train_f1)\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        val_accs.append(val_acc)\n",
    "        val_f1s.append(val_f1)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train AUC: {train_auc:.4f} | Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        adapter_ckpt = os.path.join(checkpoint, f\"epoch{epoch+1}_auc{val_auc:.4f}\")\n",
    "        model.save_pretrained(adapter_ckpt)\n",
    "        tokenizer.save_pretrained(adapter_ckpt)\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            model.save_pretrained(os.path.join(checkpoint, \"best_model\"))\n",
    "            tokenizer.save_pretrained(os.path.join(checkpoint, \"best_model\"))\n",
    "            print(f\"Best model saved: {adapter_ckpt}\")\n",
    "\n",
    "    # 손실, AUC, Accuracy, F1 곡선 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(train_aucs, label=\"Train AUC\", color='blue')\n",
    "    ax2.plot(val_aucs, label=\"Validation AUC\", color='green')\n",
    "    ax2.plot(val_accs, label=\"Validation Accuracy\", color='orange')\n",
    "    ax2.plot(val_f1s, label=\"Validation F1\", color='red')\n",
    "    ax2.set_ylabel(\"AUC / Accuracy / F1\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.title(\"Loss, AUC, Accuracy, and F1 per Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39af5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = f\"{checkpoin}/epoch3_auc0.9985\"  # ← 실제 디렉토리로 변경 필요\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73e6de72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: klue/roberta-base\n",
      "Checkpoint directory: special_tocken\n",
      "learning_rate: 0.0001\n",
      "Using device: cuda\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f9820ce8cf4935890e1e1180d10af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# train_model 호출\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, tokenizer, train_loader, val_loader, num_epochs, learning_rate, checkpoint)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     train_loss, train_acc, train_auc, train_f1, train_preds, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     val_loss, val_acc, val_auc, val_f1, val_preds, val_labels \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[1;32m     22\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[49], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     30\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     33\u001b[0m all_probs\u001b[38;5;241m.\u001b[39mextend(probs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     34\u001b[0m all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"model_name: {model_name}\")\n",
    "print(f\"Checkpoint directory: {checkpoint}\")\n",
    "print(f\"learning_rate: {learning_rate}\")\n",
    "\n",
    "# 디바이스 재확인 및 모델 디바이스 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# train_model 호출\n",
    "train_model(\n",
    "    model,\n",
    "    model_name,\n",
    "    tokenizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f54eec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, probs = [], []\n",
    "    bar = tqdm(loader, desc=\"Predicting\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            prob = F.softmax(logits, dim=1)[:, 1]  # positive 확률\n",
    "\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            probs.extend(prob.detach().float().cpu().numpy())  # bfloat16 → float32로 변환 후 numpy\n",
    "    return preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53bd6be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:37:22.513328Z",
     "iopub.status.busy": "2025-04-22T15:37:22.513083Z",
     "iopub.status.idle": "2025-04-22T15:37:22.528949Z",
     "shell.execute_reply": "2025-04-22T15:37:22.528238Z",
     "shell.execute_reply.started": "2025-04-22T15:37:22.513311Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # --- special tokens 등록 (AI/인간 판별용 확장 세트) ---\n",
    "        special_tokens = [\n",
    "            '_EOS',     # 종결어미\n",
    "            '_CON',     # 연결어미\n",
    "            '_MOD',     # 관형형 어미\n",
    "            '_SUB',     # 주격 조사\n",
    "            '_OBJ',     # 목적격 조사\n",
    "            '_ADV',     # 부사 / 부사격 조사\n",
    "            '_CONADV',  # 접속 부사\n",
    "            '_QUOTE',   # 인용격 조사\n",
    "            '_NAME',    # 고유명사\n",
    "            '_PUNCT'    # 문장부호\n",
    "        ]\n",
    "        special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "        self.tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        text = row['paragraph_text']\n",
    "        title = row['title']  # 타이틀 열\n",
    "\n",
    "        # --- 텍스트 전처리 ---\n",
    "        text = clean_text(text)\n",
    "        text = add_custom_tokens(text)  # 품사 기반 커스텀 토큰 부착\n",
    "\n",
    "        # --- 타이틀 + 본문 결합 ---\n",
    "        combined_text = f\"[TITLE] {title} [SEP] {text}\"\n",
    "\n",
    "        # --- 토큰화 ---\n",
    "        encoding = self.tokenizer(\n",
    "            combined_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids':      encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04fc8d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:37:22.530542Z",
     "iopub.status.busy": "2025-04-22T15:37:22.530380Z",
     "iopub.status.idle": "2025-04-22T15:37:22.622383Z",
     "shell.execute_reply": "2025-04-22T15:37:22.621859Z",
     "shell.execute_reply.started": "2025-04-22T15:37:22.530529Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_csv)\n",
    "test_dataset  = TestDataset(test_df, tokenizer, max_length=max_length)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33a00c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "def load_lora_model(adapter_path, torch_dtype=None):\n",
    "    \"\"\"\n",
    "    LoRA adapter 경로로부터 base model과 tokenizer를 로드하고,\n",
    "    LoRA adapter를 적용한 모델과 tokenizer 반환.\n",
    "\n",
    "    Args:\n",
    "        adapter_path (str): 저장된 LoRA adapter 디렉토리 경로\n",
    "        torch_dtype (torch.dtype, optional): 모델 로드 시 사용할 dtype (예: torch.bfloat16)\n",
    "\n",
    "    Returns:\n",
    "        model (PeftModel): LoRA adapter가 적용된 모델\n",
    "        tokenizer (AutoTokenizer): 저장된 tokenizer\n",
    "    \"\"\"\n",
    "    # 1. adapter config 로드\n",
    "    peft_config = PeftConfig.from_pretrained(adapter_path, local_files_only=True)\n",
    "\n",
    "    # 2. tokenizer 먼저 adapter_path에서 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(adapter_path, use_fast=True)\n",
    "\n",
    "    # 2. base model 로드\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        peft_config.base_model_name_or_path,\n",
    "        torch_dtype=torch_dtype\n",
    "    )\n",
    "    base_model.config.pad_token_id = base_model.config.eos_token_id\n",
    "\n",
    "    # 4. tokenizer 사이즈에 맞게 임베딩 resize\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # 3. LoRA adapter 적용\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81a745ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "load_path = f\"{checkpoint}/epoch7_auc0.7984\"\n",
    "model, tokenizer = load_lora_model(load_path, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02532a58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:48:47.623627Z",
     "iopub.status.busy": "2025-04-22T15:48:47.623032Z",
     "iopub.status.idle": "2025-04-22T15:50:41.864410Z",
     "shell.execute_reply": "2025-04-22T15:50:41.863729Z",
     "shell.execute_reply.started": "2025-04-22T15:48:47.623604Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd4cc1e83c44c6baa3a63aaef2b639c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이 저장되었습니다: /home/work/hhg/special_tocken/special_tocken_7.csv\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "pred_labels, pred_probs = predict(model, test_loader, device)\n",
    "\n",
    "sample_submission = pd.read_csv('/home/work/.datasets/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 확률로 저장\n",
    "sample_submission_probs = sample_submission.copy()\n",
    "sample_submission_probs['generated'] = pred_probs\n",
    "\n",
    "# 저장 디렉토리\n",
    "output_dir = f\"/home/work/hhg/{checkpoint}\"\n",
    "\n",
    "output_path = os.path.join(output_dir, f\"{checkpoint}_7.csv\")\n",
    "sample_submission_probs.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"파일이 저장되었습니다: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47289e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11961846,
     "sourceId": 97996,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.027726,
   "end_time": "2025-05-15T00:36:12.650211",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-15T00:35:28.622485",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
