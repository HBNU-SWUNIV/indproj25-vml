# 한밭대학교 SW중심대학 산학연계프로젝트 - LLM 기반 인간/AI 텍스트 판별 프레임워크 구축

## **팀 구성**
### 지도교수
 - 최해철 교수님

### 기업체 
 - 탑알앤디(주) 김용태 대표

### 참여학생
 - 20221123 하현경
 - 20231113 정윤선 
 - 20221106 염정석
 - 20221125 황현정

## Project Background
- ### 필요성
  - 최근 대규모 언어모델(LLM, Large Language Model)의 급속한 발전으로 인해 AI가 생성한 텍스트는 인간이 작성한 문장과의 구별이 점점 어려워지고 있음.
  - 생성형 AI의 확산과 함께 허위 정보, 자동화된 여론 조작 등 사회적 문제가 대두되면서 AI 생성 텍스트 판별 및 검증 기술의 필요성이 급격히 증가하고 있음.
  - 한국어는 형태소, 조사, 어미 변화 등 문법 구조가 복잡하여, 영어 중심의 기존 연구 결과를 그대로 적용하기 어렵기 때문에 한국어 특화 판별 모델 연구의 필요성이 높음.
- ### 기존 해결책의 문제점
  - 기존 텍스트 전처리 기법은 대부분 영어 기반 연구에 대부분이며, 이를 한국어에 직접 적용할 경우 언어적 특성을 충분히 반영되지 않아 성능 불안정해짐.
  - AI 생성 텍스트 판별 성능을 향상시키기 위한 전처리 기법 및 모델 구조 최적화 연구가 상대적으로 부족함.

      
## Case Study
#### ① 신경망 구조에 따른 판별 성능 분석 및 비교
- HC3 (Human ChatGPT Comparison) 데이터셋을 활용하여 Transformer 계열의 대표적 구조(Encoder, Decoder, Encoder-Decoder) 간 판별 성능 차이를 실험적으로 검증.
- Transformer 기반의 대표 구조인 Encoder(BERT), Decoder(GPT), Encoder-Decoder(T5) 모델을 선정하여 동일 조건에서 Fine-tuning을 수행하여 구조에 따른 성능을 비교 및 분석.

#### ② 한국어 전처리에 따른 판별 성능 분석 및 비교
- 국내 AI 경진대회 공개 데이터셋을 활용하여 다양한 한국어 전처리 기법(어휘 정규화, 불용어 제거, 품사 기반 토큰 추가 등)이 판별 성능에 미치는 영향을 비교·분석.
- 한국어의 언어적 특성을 반영하기 위해 어휘 정규화, 불용어 제거, 특정 품사 토큰 추가 등의 전처리 방식을 적용하고, 각 기법이 판별 정확도에 미치는 영향을 비교함.

  
## Conclusion
  - ### 연구 성과
    1.  T5 모델이 가장 높은 score를 기록하였으며, Encoder-Decoder 구조가 문맥 이해와 생성 패턴 분석을 동시에 수행하여 AI와 인간 텍스트의 미세한 차이를 효과적으로 식별함을 확인.
    2.  한국어 전처리 기법 중 불용어 제거 방식이 가장 높은 판별 효율성을 보임을 확인.
  
## Project Outcome
- #### 2025 년 한국방송미디어공학회 추계학술대회 
